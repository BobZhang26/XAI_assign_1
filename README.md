[![CI](https://github.com/BobZhang26/Bob_PythonTemplate1/actions/workflows/cicd.yml/badge.svg)](https://github.com/BobZhang26/Bob_PythonTemplate1/actions/workflows/cicd.yml)
## XAI Assignment 1: Explain Explainable AI
As AI systems become more integrated into decision-making processes, especially in high-stakes areas like healthcare and criminal justice, the need for explainable AI, or XAI, has become paramount. Explainable AI aims to make AI systems more transparent, providing human-understandable justifications for their decisions. However, as this paper highlights, not all explanations are inherently beneficial. While some explanations are designed with the best intentions, they can still lead to unintended negative effectsâ€”what the authors term "Explainability Pitfalls." The motivation behind this paper is to bring attention to these pitfalls, which are distinct from dark patterns.

Slides can be found [here](https://docs.google.com/presentation/d/10r_e2DXxDzeSHSfxhgGkSuZdBUf4iOHu-EOzulONTMg/edit?usp=sharing)

Watch the presentation [here](https://youtu.be/aSe9LytBvt4?si=tKGn_fYn-4o-iAdG)
